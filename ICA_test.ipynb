{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "from nilearn import masking\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.image import index_img\n",
    "from nilearn.masking import apply_mask\n",
    "\n",
    "from nilearn.image import load_img\n",
    "\n",
    "from random import sample\n",
    "from nilearn.image import index_img\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "DATADIR = pathlib.Path('/data/origami/niusha/code/local-experiment/io/ICAs')\n",
    "n_components = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_decomposition(filenames, group, i, path=DATADIR, n=n_components):\n",
    "    \"\"\"\n",
    "    This function receives nifiti images and calculates 30 independent components\n",
    "\n",
    "    inputs: \n",
    "        filenames: list of input filenames or a 4D image containing all inputs concatenated.\n",
    "        group: a group of subjects (PD/Healthy/Pooled). It is used for naming IC files.\n",
    "        path: parent directory for storing ICs.\n",
    "        i: iteration number is used for naming IC files.\n",
    "        n: number of ICs.\n",
    "\n",
    "    outputs: \n",
    "        ICA_s: A 4D image that contains 30 ICs.\n",
    "    \"\"\"\n",
    "    fast_ica = CanICA(n_components=n,\n",
    "                    memory=\"nilearn_cache\", memory_level=2,\n",
    "                    mask_strategy='whole-brain-template',\n",
    "                    do_cca=False,\n",
    "                    random_state=0)\n",
    "    fast_ica.fit(filenames)\n",
    "\n",
    "    ICA_s = fast_ica.components_img_\n",
    "    ICA_s.to_filename(path / (f'ICAs_{group}_{i}.nii.gz'))\n",
    "    return ICA_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Means_after_masking(ICAs,DBM_maps,n=n_components):\n",
    "    \"\"\"\n",
    "    This function,first extract a mask  from each IC= and then apply it on each subject.\n",
    "    After extracting regions of intrests, the function caculates mean value of these regions.\n",
    "      \n",
    "    inputs:\n",
    "        ICAs: IC components\n",
    "        DBM_maps: Target cohort\n",
    "    outputs:\n",
    "        means_after_mask: an array contains mean value of each input DBM after applying IC masks.\n",
    "    \"\"\"\n",
    "    size = DBM_maps.shape[3]\n",
    "    means_after_mask = np.zeros((n,size))\n",
    "    for i, cur_img in enumerate(iter_img(ICAs)):\n",
    "\n",
    "        mask = masking.compute_brain_mask(\n",
    "            target_img=cur_img,\n",
    "            mask_type='whole-brain',\n",
    "            )\n",
    "\n",
    "        masked_data = apply_mask(DBM_maps,mask) # is it ok to apply on whole subjects?\n",
    "        means_after_mask[i,:] = np.nanmean(masked_data,axis=1)\n",
    "        \n",
    "    return means_after_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_DBMs = load_img(\"/data/origami/niusha/out/DBM_data.nii\")\n",
    "subject_df = pd.read_csv(\"/data/origami/niusha/input/subject_IDs.csv\")\n",
    "\n",
    "N = len(subject_df.ID)\n",
    "ID_map = dict(zip(range(N),subject_df.ID))\n",
    "\n",
    "Healthy_index = np.where(subject_df.PD == 0)\n",
    "Healthy_subject = subject_df.ID.iloc[Healthy_index]\n",
    "\n",
    "PD_index = np.where(subject_df.PD == 1)\n",
    "PD_subject = subject_df.ID.iloc[PD_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vals = np.zeros((10,30))\n",
    "T_vals = np.zeros((10,30))\n",
    "\n",
    "for j in range(10):\n",
    "\n",
    "    PD_sample = sample((PD_index[0]).tolist(), len(PD_index[0]))\n",
    "    Healthy_sample = sample((Healthy_index[0]).tolist(), len(Healthy_index[0]))\n",
    "\n",
    "    PD_bootstrapped_cohort = index_img(Original_DBMs, PD_sample)\n",
    "    Healthy_bootstrapped_cohort = index_img(Original_DBMs, Healthy_sample)\n",
    "\n",
    "    PD_ICAs = ICA_decomposition(PD_bootstrapped_cohort, \"PD\", j)\n",
    "    Healthy_ICAs = ICA_decomposition(Healthy_bootstrapped_cohort, \"Healthy\", j)\n",
    "\n",
    "    PD_means = Means_after_masking(PD_ICAs,PD_bootstrapped_cohort)\n",
    "    Healthy_means = Means_after_masking(Healthy_ICAs,Healthy_bootstrapped_cohort)\n",
    "\n",
    "    for i in range(30):\n",
    "        T_vals[j,i], P_vals[j,i] = ttest_ind(PD_means[:,i], Healthy_means[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_vals_reshaped = P_vals.reshape(P_vals.shape[0], -1)\n",
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/p_values.txt\", P_vals)\n",
    "\n",
    "# T_vals_reshaped = T_vals.reshape(T_vals.shape[0], -1)\n",
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/t_stat.txt\", T_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_vals = np.loadtxt(\"/data/origami/niusha/code/local-experiment/io/t_stat.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vals_original = np.zeros((1,30))\n",
    "T_vals_original = np.zeros((1,30))\n",
    "PD_cohort = index_img(Original_DBMs, (PD_index[0]).tolist())\n",
    "Healthy_cohort = index_img(Original_DBMs, (Healthy_index[0]).tolist())\n",
    "\n",
    "PD_ICAs = ICA_decomposition(PD_cohort, \"PD\", \"\")\n",
    "Healthy_ICAs = ICA_decomposition(Healthy_cohort, \"Healthy\", \"\")\n",
    "\n",
    "PD_means = Means_after_masking(PD_ICAs,PD_cohort)\n",
    "Healthy_means = Means_after_masking(Healthy_ICAs,Healthy_cohort)\n",
    "\n",
    "for i in range(30):\n",
    "    T_vals_original[0,i], P_vals_original[0,i] = ttest_ind(PD_means[:,i], Healthy_means[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/p_values_original.txt\", P_vals_original)\n",
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/t_stat_original.txt\", T_vals_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vals_whole = np.zeros((10,30))\n",
    "T_vals_whole = np.zeros((10,30))\n",
    "\n",
    "for j in range(10):\n",
    "\n",
    "    PD_sample = sample((PD_index[0]).tolist(), len(PD_index[0]))\n",
    "    Healthy_sample = sample((Healthy_index[0]).tolist(), len(Healthy_index[0]))\n",
    "\n",
    "    PD_bootstrapped_cohort = index_img(Original_DBMs, PD_sample)\n",
    "    Healthy_bootstrapped_cohort = index_img(Original_DBMs, Healthy_sample)\n",
    "    Whole_bootstrapped_cohort = index_img(Original_DBMs, PD_sample + Healthy_sample)\n",
    "\n",
    "    whole_ICAs = ICA_decomposition(Whole_bootstrapped_cohort, \"whole\", j)\n",
    "\n",
    "    PD_means = Means_after_masking(whole_ICAs,PD_bootstrapped_cohort)\n",
    "    Healthy_means = Means_after_masking(whole_ICAs,Healthy_bootstrapped_cohort)\n",
    "\n",
    "    for i in range(30):\n",
    "        T_vals_whole[j,i], P_vals_whole[j,i] = ttest_ind(PD_means[:,i], Healthy_means[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/p_values_whole.txt\", P_vals_whole)\n",
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/t_stat_whole.txt\", T_vals_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vals_whole_original = np.zeros((1,30))\n",
    "T_vals_whole_original = np.zeros((1,30))\n",
    "\n",
    "\n",
    "PD_sample = (PD_index[0]).tolist()\n",
    "Healthy_sample = (Healthy_index[0]).tolist()\n",
    "\n",
    "PD_cohort = index_img(Original_DBMs, PD_sample)\n",
    "Healthy_cohort = index_img(Original_DBMs, Healthy_sample)\n",
    "\n",
    "whole_original_ICAs = ICA_decomposition(Original_DBMs, \"whole\", \"original\")\n",
    "\n",
    "PD_means = Means_after_masking(whole_original_ICAs,PD_cohort)\n",
    "Healthy_means = Means_after_masking(whole_original_ICAs,Healthy_cohort)\n",
    "\n",
    "for i in range(30):\n",
    "    T_vals_whole_original[0,i], P_vals_whole_original[0,i] = ttest_ind(PD_means[:,i], Healthy_means[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/p_values_whole_original.txt\", P_vals_whole_original)\n",
    "np.savetxt(\"/data/origami/niusha/code/local-experiment/io/t_stat_whole_original.txt\", T_vals_whole_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vals_whole_original_loop_test =  np.loadtxt(\"/data/origami/niusha/code/local-experiment/io/p_values_whole_original_loop_test.txt\")\n",
    "P_vals_whole_original = np.loadtxt(\"/data/origami/niusha/code/local-experiment/io/p_values_whole_original.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn.glm import threshold_stats_img\n",
    "\n",
    "# ICA_tr = threshold_stats_img(stat_img=ICAs, threshold=3.0)\n",
    "#The output is not compatible with mask and also I dont know what is the ouput of ICA. I tought it would be z stat, but when I set thr=3 I receive warning regarding the amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn.image import load_img\n",
    "\n",
    "# Original_DBMs = load_img(\"/data/origami/niusha/out/DBM_data.nii\")\n",
    "# whole_original_ICAs = load_img(\"/data/origami/niusha/code/local-experiment/io/ICAs/ICAs_whole_original.nii.gz\")\n",
    "# cur_img = index_img(whole_original_ICAs, 1)\n",
    "# # cur_img = whole_original_ICAs\n",
    "# # nifti_masker = maskers.NiftiMasker(\n",
    "# #             mask_img=None,\n",
    "# #             standardize='zscore',\n",
    "# #             t_r=3,\n",
    "# #             mask_strategy='whole-brain-template',\n",
    "# #             memory=\"nilearn_cache\",\n",
    "# #             )\n",
    "# from nilearn import masking\n",
    "# from nilearn.masking import apply_mask\n",
    "# #what should be the threshold\n",
    "# mask = masking.compute_brain_mask(\n",
    "#             target_img=cur_img,\n",
    "#             mask_type='whole-brain',\n",
    "#             )\n",
    "\n",
    "# one_subject = index_img(Original_DBMs,1)\n",
    "# masked_data = apply_mask(one_subject,mask)\n",
    "# # masked_data = nifti_masker.fit_transform(one_subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('py10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3b4f043148b4a13befb1abc563824184ef59f528a35c0fb335f883535f60f47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
